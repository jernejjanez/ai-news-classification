BBC Clean:
	Shape of dataset  (2225, 2)
	Index(['category', 'text'], dtype='object')
	No. of unique classes 5
	Total 400000 word vectors in Glove 6B 100d.
	Shape of Data Tensor: (2225, 1000)
	Shape of Label Tensor: (2225, 5)
	Shape of x train (1780, 1000)
	Shape of y train (1780, 5)
	Shape of x val (445, 1000)
	Shape of y val (445, 5)
	Number of Unique Tokens 23385

	Simplified convolutional neural network
	_________________________________________________________________
	Layer (type)                 Output Shape              Param #   
	=================================================================
	input_1 (InputLayer)         (None, 1000)              0         
	_________________________________________________________________
	embedding_1 (Embedding)      (None, 1000, 100)         2338600   
	_________________________________________________________________
	conv1d_1 (Conv1D)            (None, 996, 128)          64128     
	_________________________________________________________________
	max_pooling1d_1 (MaxPooling1 (None, 199, 128)          0         
	_________________________________________________________________
	conv1d_2 (Conv1D)            (None, 195, 128)          82048     
	_________________________________________________________________
	max_pooling1d_2 (MaxPooling1 (None, 39, 128)           0         
	_________________________________________________________________
	conv1d_3 (Conv1D)            (None, 35, 128)           82048     
	_________________________________________________________________
	max_pooling1d_3 (MaxPooling1 (None, 1, 128)            0         
	_________________________________________________________________
	flatten_1 (Flatten)          (None, 128)               0         
	_________________________________________________________________
	dense_1 (Dense)              (None, 128)               16512     
	_________________________________________________________________
	dense_2 (Dense)              (None, 5)                 645       
	=================================================================
	Total params: 2,583,981
	Trainable params: 2,583,981
	Non-trainable params: 0

	Train on 1780 samples, validate on 445 samples

	Epoch 1/15
	1780/1780 [==============================] - 32s 18ms/step - loss: 1.6304 - acc: 0.2135 - val_loss: 1.6036 - val_acc: 0.2584
	Epoch 00001: val_acc improved from -inf to 0.25843

	Epoch 2/15
	1780/1780 [==============================] - 30s 17ms/step - loss: 1.6102 - acc: 0.2298 - val_loss: 1.6114 - val_acc: 0.2562
	Epoch 00002: val_acc did not improve from 0.25843

	Epoch 3/15
	1780/1780 [==============================] - 31s 17ms/step - loss: 1.5838 - acc: 0.2775 - val_loss: 1.5365 - val_acc: 0.2697
	Epoch 00003: val_acc improved from 0.25843 to 0.26966

	Epoch 4/15
	1780/1780 [==============================] - 31s 18ms/step - loss: 1.4955 - acc: 0.3528 - val_loss: 1.6065 - val_acc: 0.2539
	Epoch 00004: val_acc did not improve from 0.26966

	Epoch 5/15
	1780/1780 [==============================] - 31s 17ms/step - loss: 1.3440 - acc: 0.4607 - val_loss: 1.5109 - val_acc: 0.3303
	Epoch 00005: val_acc improved from 0.26966 to 0.33034

	Epoch 6/15
	1780/1780 [==============================] - 30s 17ms/step - loss: 1.2065 - acc: 0.5213 - val_loss: 1.4329 - val_acc: 0.4382
	Epoch 00006: val_acc improved from 0.33034 to 0.43820

	Epoch 7/15
	1780/1780 [==============================] - 31s 17ms/step - loss: 1.0694 - acc: 0.5983 - val_loss: 1.2907 - val_acc: 0.4652
	Epoch 00007: val_acc improved from 0.43820 to 0.46517

	Epoch 8/15
	1780/1780 [==============================] - 32s 18ms/step - loss: 0.9177 - acc: 0.6365 - val_loss: 1.2634 - val_acc: 0.5101
	Epoch 00008: val_acc improved from 0.46517 to 0.51011

	Epoch 9/15
	1780/1780 [==============================] - 31s 18ms/step - loss: 0.7722 - acc: 0.7140 - val_loss: 1.4986 - val_acc: 0.4539
	Epoch 00009: val_acc did not improve from 0.51011

	Epoch 10/15
	1780/1780 [==============================] - 30s 17ms/step - loss: 0.6648 - acc: 0.7567 - val_loss: 2.2501 - val_acc: 0.3079
	Epoch 00010: val_acc did not improve from 0.51011

	Epoch 11/15
	1780/1780 [==============================] - 31s 17ms/step - loss: 0.5572 - acc: 0.8034 - val_loss: 1.6810 - val_acc: 0.4742
	Epoch 00011: val_acc did not improve from 0.51011

	Epoch 12/15
	1780/1780 [==============================] - 32s 18ms/step - loss: 0.4511 - acc: 0.8360 - val_loss: 1.8551 - val_acc: 0.4652
	Epoch 00012: val_acc did not improve from 0.51011

	Epoch 13/15
	1780/1780 [==============================] - 30s 17ms/step - loss: 0.3588 - acc: 0.8635 - val_loss: 1.5192 - val_acc: 0.5775
	Epoch 00013: val_acc improved from 0.51011 to 0.57753

	Epoch 14/15
	1780/1780 [==============================] - 35s 19ms/step - loss: 0.2692 - acc: 0.9073 - val_loss: 1.7030 - val_acc: 0.5236
	Epoch 00014: val_acc did not improve from 0.57753

	Epoch 15/15
	1780/1780 [==============================] - 36s 20ms/step - loss: 0.2276 - acc: 0.9225 - val_loss: 1.8859 - val_acc: 0.5820
	Epoch 00015: val_acc improved from 0.57753 to 0.58202

	F1 (macro): 0.853748
	F1 (micro): 0.855730
	F1 (weighted): 0.857012

5 categories cleaned with min 20 words:
	F1 (macro): 0.569629
	F1 (micro): 0.693538
	F1 (weighted): 0.687570

5 categories cleaned:


5 categories cleaned using bbc_clean model:
	F1 (macro): 0.300364
	F1 (micro): 0.443238
	F1 (weighted): 0.447946

BBC Clean using 5 categories cleaned model:
	F1 (macro): 0.341875
	F1 (micro): 0.385618
	F1 (weighted): 0.345370